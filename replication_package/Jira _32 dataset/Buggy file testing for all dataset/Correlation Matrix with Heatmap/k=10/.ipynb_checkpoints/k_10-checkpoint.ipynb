{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f0d061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total file:  32\n",
      "\n",
      "===================\n",
      "\n",
      "Processing File:  /Users/saumenduroy/Desktop/TOSEM_replicationpackage/data_jira/activemq-5.2.0.csv\n"
     ]
    }
   ],
   "source": [
    "## Load Data and preparing datasets\n",
    "\n",
    "# Import for Load Data\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "\n",
    "# Import for Split Data into Training and Testing Samples\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import subprocess\n",
    "import sys\n",
    "import importlib\n",
    "import numpy\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pyBreakDown.explainer import Explainer\n",
    "from pyBreakDown.explanation import Explanation\n",
    "from pyexplainer.pyexplainer_pyexplainer import PyExplainer\n",
    "import io\n",
    "import contextlib\n",
    "import re\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# feature agreement\n",
    "def calculate_task1(dict1, dict2):\n",
    "    if len(dict1) == 0 or len(dict2) == 0:\n",
    "        return 0.00\n",
    "    keys1 = set(dict1.keys())\n",
    "    keys2 = set(dict2.keys())\n",
    "    common_keys = len(keys1.intersection(keys2))\n",
    "    return common_keys / max(len(dict1), len(dict2))\n",
    "\n",
    "# Rank Agreement\n",
    "def calculate_task2(dict1, dict2):\n",
    "    if len(dict1) == 0 or len(dict2) == 0:\n",
    "        return 0.00\n",
    "    keys1 = list(dict1.keys())\n",
    "    keys2 = list(dict2.keys())\n",
    "    common_keys = 0\n",
    "    for i in range(min(len(keys1), len(keys2))):\n",
    "        if keys1[i] == keys2[i]:\n",
    "            common_keys += 1\n",
    "    return common_keys / max(len(dict1), len(dict2))\n",
    "\n",
    "# Sign Agreement\n",
    "def calculate_task3(dict1, dict2):\n",
    "    if len(dict1) == 0 or len(dict2) == 0:\n",
    "        return 0.00\n",
    "    common_signs = 0\n",
    "    total_common = 0\n",
    "    for key in dict1:\n",
    "        if key in dict2:\n",
    "            if dict1[key] * dict2[key] > 0:\n",
    "                common_signs += 1\n",
    "            total_common += 1\n",
    "    if total_common == 0:\n",
    "        return 0.00\n",
    "    return common_signs / total_common\n",
    "\n",
    "file_list = glob(\"/Users/saumenduroy/Desktop/TOSEM_replicationpackage/data_jira/*.csv\")\n",
    "tested_file = []\n",
    "print(\"Total file: \", len(file_list))\n",
    "\n",
    "for file in file_list:\n",
    "    print(\"\\n===================\\n\")\n",
    "    print(\"Processing File: \", file)\n",
    "    main_file=file\n",
    "    train_dataset = pd.read_csv(file, index_col = 'File')\n",
    "    \n",
    "    test_data_list = [f for f in file_list if f != file]\n",
    "    test_dataset = pd.DataFrame(columns=[\"File\"]+train_dataset.columns.values.tolist())\n",
    "    for test_file in test_data_list:\n",
    "        tmp_df = pd.read_csv(test_file)\n",
    "        test_dataset = pd.DataFrame(np.concatenate([test_dataset.values, tmp_df.values]), columns=tmp_df.columns)\n",
    "    test_dataset.set_index(\"File\", inplace=True)\n",
    "    outcome = 'RealBug'\n",
    "    features = ['ADEV', 'CountDeclMethod', 'MAJOR_COMMIT', 'CountSemicolon', 'SumCyclomatic', 'CountStmt', 'CountLineCode','AvgLine', 'AvgLineBlank', 'AvgCyclomatic']\n",
    "    # commits - # of commits that modify the file of interest\n",
    "    # Added lines - # of added lines of code\n",
    "    # Count class coupled - # of classes that interact or couple with the class of interest\n",
    "    # LOC - # of lines of code\n",
    "    # RatioCommentToCode - The ratio of lines of comments to lines of code\n",
    "\n",
    "    # process outcome to 0 and 1\n",
    "    train_dataset[outcome] = pd.Categorical(train_dataset[outcome])\n",
    "    train_dataset[outcome] = train_dataset[outcome].cat.codes\n",
    "\n",
    "    test_dataset[outcome] = pd.Categorical(test_dataset[outcome])\n",
    "    test_dataset[outcome] = test_dataset[outcome].cat.codes\n",
    "\n",
    "    X_train = train_dataset.loc[:, features]\n",
    "    X_test = test_dataset.loc[:, features]\n",
    "\n",
    "    y_train = train_dataset.loc[:, outcome]\n",
    "    y_test = test_dataset.loc[:, outcome]\n",
    "\n",
    "    class_labels = ['Clean', 'Defective']\n",
    "\n",
    "    X_train.columns = features\n",
    "    X_test.columns = features\n",
    "    training_data = pd.concat([X_train, y_train], axis=1)\n",
    "    testing_data = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "    our_rf_model = RandomForestClassifier(random_state=0)\n",
    "    our_rf_model.fit(X_train, y_train)  \n",
    "    \n",
    "    #### LIME\n",
    "\n",
    "    # Import for LIME\n",
    "    \n",
    "    \n",
    "    file_to_be_explained = \"\"\n",
    "    \n",
    "    worked = True\n",
    "    \n",
    "    while worked:\n",
    "        try:\n",
    "            \n",
    "            random_file = random.choice(testing_data.index.values.tolist())\n",
    "            lime_thres = 0.67\n",
    "            if random_file in tested_file:\n",
    "                continue\n",
    "            if \"jruby-1.7.0.preview1.csv\" in file:\n",
    "                random_file=\"hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/HBaseServer.java\"\n",
    "                lime_thres = 0.5\n",
    "            file_to_be_explained = random_file\n",
    "            # LIME Step 1 - Construct an explainer\n",
    "            our_lime_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "                                        training_data = X_train.values,  \n",
    "                                        mode = 'classification',\n",
    "                                        training_labels = y_train,\n",
    "                                        feature_names = features,\n",
    "                                        class_names = class_labels,\n",
    "                                        discretize_continuous = True)\n",
    "\n",
    "            # LIME Step 2 - Use the constructed explainer with the predict function \n",
    "            # of your predictive model to explain any instance\n",
    "            lime_local_explanation_of_an_instance = our_lime_explainer.explain_instance(\n",
    "                                       # X_test[0],\n",
    "                                      # data_row = X_test.loc['FileName.py', : ], \n",
    "                                        data_row = X_test.loc[file_to_be_explained, : ],\n",
    "                                        predict_fn = our_rf_model.predict_proba, \n",
    "                                        num_features = len(features),\n",
    "                                        top_labels = 1)\n",
    "\n",
    "            #explainer = lime_tabular.LimeTabularExplainer(X_train, mode = \"regression\", feature_names = boston_housing.feature_names)\n",
    "            #explanation = explainer.explain_instance(X_test[0], model.predict, num_features = len(boston_housing.feature_names))\n",
    "            lime_prob = lime_local_explanation_of_an_instance.predict_proba\n",
    "            if \"jruby-1.7.0.preview1.csv\" in file:\n",
    "                print(\"lime_prob: \", lime_prob)\n",
    "            if lime_prob[1] >= lime_thres:\n",
    "                print(f'Explaining {file_to_be_explained} with LIME')\n",
    "                lime_results = lime_local_explanation_of_an_instance.as_list()\n",
    "                lime_dict = {}\n",
    "                for results in lime_results:\n",
    "                    feat = \"\"\n",
    "                    for r in results:\n",
    "                        ignoring_sym = [\">=\", \">\", \"<=\", \"<\", \"=\"]\n",
    "                        if isinstance(r, str):\n",
    "                            feat = re.sub(r'[^a-zA-Z\\s_]', '', r).rstrip().lstrip()\n",
    "                        else:\n",
    "                            if r >= 0:\n",
    "                                lime_dict[feat] = 1\n",
    "                            else:\n",
    "                                lime_dict[feat] = -1\n",
    "                print(lime_dict)\n",
    "            \n",
    "                # Please use the code below to visualise the generated LIME explanation.\n",
    "                ### save lime output\n",
    "                # lime_local_explanation_of_an_instance.show_in_notebook()\n",
    "                \n",
    "                \n",
    "                ### SHAP:\n",
    "                file_to_be_explained_idx = list(X_test.index).index(file_to_be_explained)\n",
    "                explainer = shap.Explainer(our_rf_model)\n",
    "                shap_values = explainer(X_test)\n",
    "                # shap.plots.bar(shap_values[file_to_be_explained_idx, :, 1], show=True)\n",
    "                explain_file_val = shap_values[file_to_be_explained_idx, :, 1].values.tolist()\n",
    "                shap_dict = {}\n",
    "                test_columns = X_test.columns.values.tolist()\n",
    "                for col_index in range(0, len(test_columns)):\n",
    "                    shap_dict[test_columns[col_index]] = explain_file_val[col_index]\n",
    "                sorted_shap_dict = dict(sorted(shap_dict.items(), key=lambda item: abs(item[1]), reverse=True))\n",
    "                for keys in sorted_shap_dict.keys():\n",
    "                    if sorted_shap_dict[keys] >= 0:\n",
    "                        sorted_shap_dict[keys] = 1\n",
    "                    else:\n",
    "                        sorted_shap_dict[keys] = -1\n",
    "                print(sorted_shap_dict)\n",
    "                \n",
    "                \n",
    "                #Breakdown\n",
    "                our_rf_model = RandomForestClassifier(random_state=0)\n",
    "                our_rf_model.fit(X_train, y_train)\n",
    "                #make explainer object\n",
    "                exp = Explainer(clf=our_rf_model, data= X_train, colnames=features)\n",
    "                #make explanation object that contains all information\n",
    "                explanation = exp.explain(observation=X_test.iloc[file_to_be_explained_idx,:].values,direction=\"up\",useIntercept=True)\n",
    "                # explanation.visualize()\n",
    "                output_buffer = io.StringIO()\n",
    "                with contextlib.redirect_stdout(output_buffer):\n",
    "                    explanation.text()\n",
    "\n",
    "                captured_output = output_buffer.getvalue()\n",
    "                with open(\"test.txt\", \"w\") as file:\n",
    "                    file.write(captured_output)\n",
    "                    \n",
    "                breakdown_df = pd.read_csv(\"test.txt\", sep='\\t')\n",
    "                \n",
    "                counter=-1\n",
    "                breakdown_dict={}\n",
    "                for _, row in breakdown_df.iterrows():\n",
    "                    counter+=1\n",
    "                    if counter < 1:\n",
    "                        continue\n",
    "                    row_val = row.values.tolist()\n",
    "                    row_val = row_val[0].split(\" \")\n",
    "                    row_val_main = []\n",
    "                    for c in row_val:\n",
    "                        if len(c) == 0 or c == \"=\":\n",
    "                            continue\n",
    "                        row_val_main.append(c)\n",
    "                    if float(row_val_main[2]) >= 0:\n",
    "                        breakdown_dict[row_val_main[0]] = 1\n",
    "                    else:\n",
    "                        breakdown_dict[row_val_main[0]] = -1\n",
    "                    if counter == len(features):\n",
    "                        break\n",
    "                print(breakdown_dict)\n",
    "                \n",
    "                \n",
    "                #### pyexplainer\n",
    "                rf_model = RandomForestClassifier(random_state=0)\n",
    "                rf_model.fit(X_train, y_train) \n",
    "                np.random.seed(0)\n",
    "                pyexp = PyExplainer(X_train = X_train,\n",
    "                                           y_train = y_train,\n",
    "                                           indep = X_train.columns,\n",
    "                                           dep = outcome,\n",
    "                                           top_k_rules=5,\n",
    "                                           blackbox_model = rf_model)\n",
    "\n",
    "                # PyExplainer Step 2 - Generate the rule-based explanation of an instance to be explained\n",
    "                exp_obj = pyexp.explain(X_explain = X_test.loc[file_to_be_explained,:].to_frame().transpose(),\n",
    "                                        y_explain = pd.Series(bool(y_test.loc[file_to_be_explained]), \n",
    "                                                                      index = [file_to_be_explained],\n",
    "                                                                      name = outcome),\n",
    "                                        search_function = 'crossoverinterpolation',\n",
    "                                        max_iter=1000,\n",
    "                                        max_rules=20,\n",
    "                                        random_state=0,\n",
    "                                        reuse_local_model=True)\n",
    "\n",
    "                # Please use the code below to visualise the generated PyExplainer explanation (What-If interactive visualisation).\n",
    "                pyexp.visualise(exp_obj, title=\"Why this file is predicted as defect-introducing?\")\n",
    "                top_rules = pyexp.parse_top_rules(exp_obj['top_k_positive_rules'],exp_obj['top_k_negative_rules'])['top_tofollow_rules']\n",
    "                bullet_data = pyexp.generate_bullet_data(pyexp.parse_top_rules(exp_obj['top_k_positive_rules'],exp_obj['top_k_negative_rules']))\n",
    "                pyexp_dict = {}\n",
    "                for rules in range(0, len(top_rules)):\n",
    "                    variable = top_rules[rules]['variable']\n",
    "                    value = float(top_rules[rules]['value'])\n",
    "                    marker = bullet_data[rules]['markers'][0]\n",
    "                    if top_rules[rules]['lessthan']:\n",
    "                        if marker <= value:\n",
    "                            pyexp_dict[variable] = 1\n",
    "                        else:\n",
    "                            pyexp_dict[variable] = -1\n",
    "                    else:\n",
    "                        if marker > value:\n",
    "                            pyexp_dict[variable] = 1\n",
    "                        else:\n",
    "                            pyexp_dict[variable] = -1\n",
    "\n",
    "                print(pyexp_dict)\n",
    "                worked=False\n",
    "                tested_file.append(file_to_be_explained)\n",
    "                    \n",
    "                data_task1 = np.array([\n",
    "                    [calculate_task1(lime_dict, lime_dict), calculate_task1(lime_dict, sorted_shap_dict), calculate_task1(lime_dict, breakdown_dict), calculate_task1(lime_dict, pyexp_dict)],\n",
    "                    [calculate_task1(sorted_shap_dict, lime_dict), calculate_task1(sorted_shap_dict, sorted_shap_dict), calculate_task1(sorted_shap_dict, breakdown_dict), calculate_task1(sorted_shap_dict, pyexp_dict)],\n",
    "                    [calculate_task1(breakdown_dict, lime_dict), calculate_task1(breakdown_dict, sorted_shap_dict), calculate_task1(breakdown_dict, breakdown_dict), calculate_task1(breakdown_dict, pyexp_dict)],\n",
    "                    [calculate_task1(pyexp_dict, lime_dict), calculate_task1(pyexp_dict, sorted_shap_dict), calculate_task1(pyexp_dict, breakdown_dict), calculate_task1(pyexp_dict, pyexp_dict)]\n",
    "                ])\n",
    "\n",
    "                data_task2 = np.array([\n",
    "                    [calculate_task2(lime_dict, lime_dict), calculate_task2(lime_dict, sorted_shap_dict), calculate_task2(lime_dict, breakdown_dict), calculate_task2(lime_dict, pyexp_dict)],\n",
    "                    [calculate_task2(sorted_shap_dict, lime_dict), calculate_task2(sorted_shap_dict, sorted_shap_dict), calculate_task2(sorted_shap_dict, breakdown_dict), calculate_task2(sorted_shap_dict, pyexp_dict)],\n",
    "                    [calculate_task2(breakdown_dict, lime_dict), calculate_task2(breakdown_dict, sorted_shap_dict), calculate_task2(breakdown_dict, breakdown_dict), calculate_task2(breakdown_dict, pyexp_dict)],\n",
    "                    [calculate_task2(pyexp_dict, lime_dict), calculate_task2(pyexp_dict, sorted_shap_dict), calculate_task2(pyexp_dict, breakdown_dict), calculate_task2(pyexp_dict, pyexp_dict)]\n",
    "                ])\n",
    "\n",
    "                data_task3 = np.array([\n",
    "                    [calculate_task3(lime_dict, lime_dict), calculate_task3(lime_dict, sorted_shap_dict), calculate_task3(lime_dict, breakdown_dict), calculate_task3(lime_dict, pyexp_dict)],\n",
    "                    [calculate_task3(sorted_shap_dict, lime_dict), calculate_task3(sorted_shap_dict, sorted_shap_dict), calculate_task3(sorted_shap_dict, breakdown_dict), calculate_task3(sorted_shap_dict, pyexp_dict)],\n",
    "                    [calculate_task3(breakdown_dict, lime_dict), calculate_task3(breakdown_dict, sorted_shap_dict), calculate_task3(breakdown_dict, breakdown_dict), calculate_task3(breakdown_dict, pyexp_dict)],\n",
    "                    [calculate_task3(pyexp_dict, lime_dict), calculate_task3(pyexp_dict, sorted_shap_dict), calculate_task3(pyexp_dict, breakdown_dict), calculate_task3(pyexp_dict, pyexp_dict)]\n",
    "                ])\n",
    "\n",
    "                # Row and column labels\n",
    "                pairs = [\"LIME\", \"SHAP\", \"BreakDown\", \"PyExplainer\"]\n",
    "                tasks = [\"Feature Agreement\", \"Rank Agreement\", \"Sign Agreement\"]\n",
    "\n",
    "                # Create the figure and subplots\n",
    "                fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "                fig.suptitle(\"Processing file: \"+main_file.split(\"/\")[-1])\n",
    "\n",
    "                # Plot heatmap for FA\n",
    "                sns.heatmap(data_task1, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=.5, xticklabels=pairs, yticklabels=pairs, ax=axes[0])\n",
    "                axes[0].set_title(tasks[0] + \" (When k=\"+str(len(features))+\")\")\n",
    "                \n",
    "                # Plot heatmap for SA\n",
    "                sns.heatmap(data_task3, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=.5, xticklabels=pairs, yticklabels=pairs, ax=axes[1])\n",
    "                axes[1].set_title(tasks[2] + \" (When k=\"+str(len(features))+\")\")\n",
    "\n",
    "                # Plot heatmap for RA\n",
    "                sns.heatmap(data_task2, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=.5, xticklabels=pairs, yticklabels=pairs, ax=axes[2])\n",
    "                axes[2].set_title(tasks[1] + \" (When k=\"+str(len(features))+\")\")\n",
    "\n",
    "                plt.tight_layout()\n",
    "                fig_file_name = main_file.split(\"/\")[-1].replace(\".\", \"_\")+\"-\"+file_to_be_explained.replace(\"/\", \"_\").replace(\".\",\"_\")+\"_fa_ra_sa_plot.png\"\n",
    "                plt.savefig(fig_file_name)\n",
    "                \n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "        except Exception as e:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7c1354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79dfcc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e209ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58390c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ca6e62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a4e3a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa531186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e6cacd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
