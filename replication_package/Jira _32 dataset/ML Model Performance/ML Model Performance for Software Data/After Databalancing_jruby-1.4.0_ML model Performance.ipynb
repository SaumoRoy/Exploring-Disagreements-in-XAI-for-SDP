{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da61d3a8",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "418ae83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import lime\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn import tree\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import make_regression\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e346c8f",
   "metadata": {},
   "source": [
    "## Dataset Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cef3bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(('/Users/saumenduroy/Desktop/Defect_Detection/data/lucene-2.9.0.csv'), index_col = 'File')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd8a556",
   "metadata": {},
   "source": [
    "## Select a specific row or column from the dataset and dataset splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88853fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccd18ea",
   "metadata": {},
   "source": [
    "## Dataset Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81f12468",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "051eb525",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "oversample =  RandomOverSampler()\n",
    "X_train,y_train = oversample.fit_resample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b7b0507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 767,\n",
       "         1: 767,\n",
       "         3: 767,\n",
       "         4: 767,\n",
       "         2: 767,\n",
       "         11: 767,\n",
       "         12: 767,\n",
       "         6: 767,\n",
       "         8: 767,\n",
       "         5: 767})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db4cd15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 328, 4: 5, 1: 41, 3: 11, 2: 20, 5: 2, 9: 1, 6: 2, 8: 1})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7245370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train shape:  (7670, 68)\n",
      "Train label shape:  (7670,)\n",
      "X_Test shape:  (411, 68)\n",
      "Test label shape:  (411,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_Train shape: \", X_train.shape)\n",
    "print(\"Train label shape: \", y_train.shape)\n",
    "print(\"X_Test shape: \", X_test.shape)\n",
    "print(\"Test label shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c2f65bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CountDeclMethodPrivate</th>\n",
       "      <th>AvgLineCode</th>\n",
       "      <th>CountLine</th>\n",
       "      <th>MaxCyclomatic</th>\n",
       "      <th>CountDeclMethodDefault</th>\n",
       "      <th>AvgEssential</th>\n",
       "      <th>CountDeclClassVariable</th>\n",
       "      <th>SumCyclomaticStrict</th>\n",
       "      <th>AvgCyclomatic</th>\n",
       "      <th>AvgLine</th>\n",
       "      <th>...</th>\n",
       "      <th>Del_lines</th>\n",
       "      <th>OWN_LINE</th>\n",
       "      <th>OWN_COMMIT</th>\n",
       "      <th>MINOR_COMMIT</th>\n",
       "      <th>MINOR_LINE</th>\n",
       "      <th>MAJOR_COMMIT</th>\n",
       "      <th>MAJOR_LINE</th>\n",
       "      <th>HeuBug</th>\n",
       "      <th>HeuBugCount</th>\n",
       "      <th>RealBug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>329</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.945289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>269</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.988848</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>327</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.694190</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7665</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>1811</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>226</td>\n",
       "      <td>0.685809</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7666</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>1811</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>226</td>\n",
       "      <td>0.685809</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7667</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>1811</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>226</td>\n",
       "      <td>0.685809</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7668</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>1811</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>226</td>\n",
       "      <td>0.685809</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7669</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>1811</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>226</td>\n",
       "      <td>0.685809</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7670 rows Ã— 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CountDeclMethodPrivate  AvgLineCode  CountLine  MaxCyclomatic  \\\n",
       "0                          0            6         55              3   \n",
       "1                          0           14        329              5   \n",
       "2                          0           11        269              4   \n",
       "3                          0            1         34              1   \n",
       "4                          1           14        327              2   \n",
       "...                      ...          ...        ...            ...   \n",
       "7665                       7           15       1811              6   \n",
       "7666                       7           15       1811              6   \n",
       "7667                       7           15       1811              6   \n",
       "7668                       7           15       1811              6   \n",
       "7669                       7           15       1811              6   \n",
       "\n",
       "      CountDeclMethodDefault  AvgEssential  CountDeclClassVariable  \\\n",
       "0                          1             2                       0   \n",
       "1                          2             2                       2   \n",
       "2                          0             1                       0   \n",
       "3                          0             1                       0   \n",
       "4                          0             1                       0   \n",
       "...                      ...           ...                     ...   \n",
       "7665                       5             1                       3   \n",
       "7666                       5             1                       3   \n",
       "7667                       5             1                       3   \n",
       "7668                       5             1                       3   \n",
       "7669                       5             1                       3   \n",
       "\n",
       "      SumCyclomaticStrict  AvgCyclomatic  AvgLine  ...  Del_lines  OWN_LINE  \\\n",
       "0                       6              2        6  ...          0  1.000000   \n",
       "1                      13              4       14  ...          0  0.945289   \n",
       "2                      21              3       44  ...          0  0.988848   \n",
       "3                       2              1        1  ...          0  0.941176   \n",
       "4                      20              1       18  ...          4  0.694190   \n",
       "...                   ...            ...      ...  ...        ...       ...   \n",
       "7665                  151              1       19  ...        226  0.685809   \n",
       "7666                  151              1       19  ...        226  0.685809   \n",
       "7667                  151              1       19  ...        226  0.685809   \n",
       "7668                  151              1       19  ...        226  0.685809   \n",
       "7669                  151              1       19  ...        226  0.685809   \n",
       "\n",
       "      OWN_COMMIT  MINOR_COMMIT  MINOR_LINE  MAJOR_COMMIT  MAJOR_LINE  HeuBug  \\\n",
       "0            0.0             0           1             0           0   False   \n",
       "1            0.0             0           1             0           5   False   \n",
       "2            1.0             0           1             1           1   False   \n",
       "3            1.0             0           2             1           0   False   \n",
       "4            0.5             0           3             2           4    True   \n",
       "...          ...           ...         ...           ...         ...     ...   \n",
       "7665         0.7             0           2             3           6    True   \n",
       "7666         0.7             0           2             3           6    True   \n",
       "7667         0.7             0           2             3           6    True   \n",
       "7668         0.7             0           2             3           6    True   \n",
       "7669         0.7             0           2             3           6    True   \n",
       "\n",
       "      HeuBugCount  RealBug  \n",
       "0               0    False  \n",
       "1               0    False  \n",
       "2               0    False  \n",
       "3               0    False  \n",
       "4               1     True  \n",
       "...           ...      ...  \n",
       "7665            3     True  \n",
       "7666            3     True  \n",
       "7667            3     True  \n",
       "7668            3     True  \n",
       "7669            3     True  \n",
       "\n",
       "[7670 rows x 68 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e3fced5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CountDeclMethodPrivate', 'AvgLineCode', 'CountLine', 'MaxCyclomatic',\n",
       "       'CountDeclMethodDefault', 'AvgEssential', 'CountDeclClassVariable',\n",
       "       'SumCyclomaticStrict', 'AvgCyclomatic', 'AvgLine',\n",
       "       'CountDeclClassMethod', 'AvgLineComment', 'AvgCyclomaticModified',\n",
       "       'CountDeclFunction', 'CountLineComment', 'CountDeclClass',\n",
       "       'CountDeclMethod', 'SumCyclomaticModified', 'CountLineCodeDecl',\n",
       "       'CountDeclMethodProtected', 'CountDeclInstanceVariable',\n",
       "       'MaxCyclomaticStrict', 'CountDeclMethodPublic', 'CountLineCodeExe',\n",
       "       'SumCyclomatic', 'SumEssential', 'CountStmtDecl', 'CountLineCode',\n",
       "       'CountStmtExe', 'RatioCommentToCode', 'CountLineBlank', 'CountStmt',\n",
       "       'MaxCyclomaticModified', 'CountSemicolon', 'AvgLineBlank',\n",
       "       'CountDeclInstanceMethod', 'AvgCyclomaticStrict',\n",
       "       'PercentLackOfCohesion', 'MaxInheritanceTree', 'CountClassDerived',\n",
       "       'CountClassCoupled', 'CountClassBase', 'CountInput_Max',\n",
       "       'CountInput_Mean', 'CountInput_Min', 'CountOutput_Max',\n",
       "       'CountOutput_Mean', 'CountOutput_Min', 'CountPath_Max',\n",
       "       'CountPath_Mean', 'CountPath_Min', 'MaxNesting_Max', 'MaxNesting_Mean',\n",
       "       'MaxNesting_Min', 'COMM', 'ADEV', 'DDEV', 'Added_lines', 'Del_lines',\n",
       "       'OWN_LINE', 'OWN_COMMIT', 'MINOR_COMMIT', 'MINOR_LINE', 'MAJOR_COMMIT',\n",
       "       'MAJOR_LINE', 'HeuBug', 'HeuBugCount', 'RealBug', 'RealBugCount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78546eb8",
   "metadata": {},
   "source": [
    "## Checking the null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "523d044d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountDeclMethodPrivate    0\n",
       "AvgLineCode               0\n",
       "CountLine                 0\n",
       "MaxCyclomatic             0\n",
       "CountDeclMethodDefault    0\n",
       "                         ..\n",
       "MAJOR_LINE                0\n",
       "HeuBug                    0\n",
       "HeuBugCount               0\n",
       "RealBug                   0\n",
       "RealBugCount              0\n",
       "Length: 69, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d165c133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[df.dtypes == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "729dbb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountDeclMethodPrivate    int64\n",
       "AvgLineCode               int64\n",
       "CountLine                 int64\n",
       "MaxCyclomatic             int64\n",
       "CountDeclMethodDefault    int64\n",
       "                          ...  \n",
       "MAJOR_LINE                int64\n",
       "HeuBug                     bool\n",
       "HeuBugCount               int64\n",
       "RealBug                    bool\n",
       "RealBugCount              int64\n",
       "Length: 69, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f3d8749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#our_rf_model = RandomForestClassifier(random_state=0)\n",
    "#our_rf_model.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fb9189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For SVM data fitting\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b6a273",
   "metadata": {},
   "source": [
    "## Create classifier object, Train, and Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02fa0141",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
     ]
    }
   ],
   "source": [
    "# Create classifer object\n",
    "our_rf_model = RandomForestClassifier()\n",
    "our_dt_model = DecisionTreeClassifier()\n",
    "our_lr_model = LogisticRegression()\n",
    "our_mlp_model = MLPClassifier()\n",
    "our_xgb_model = XGBClassifier()\n",
    "our_svm_model = svm.SVC()\n",
    "\n",
    "# Train Classifer\n",
    "our_rf_model = our_rf_model.fit(X_train,y_train)\n",
    "our_dt_model = our_dt_model.fit(X_train,y_train)\n",
    "our_lr_model = our_lr_model.fit(X_train,y_train)\n",
    "our_mlp_model = our_mlp_model.fit(X_train,y_train)\n",
    "our_xgb_model = our_xgb_model.fit(X_train,y_train)\n",
    "our_svm_model = our_svm_model.fit(X_train [:500], y_train[:500])\n",
    "\n",
    "#Predict the response for test dataset\n",
    "\n",
    "y_pred_our_rf_model = our_rf_model.predict(X_test)\n",
    "y_pred_our_dt_model = our_dt_model.predict(X_test)\n",
    "y_pred_our_lr_model = our_lr_model.predict(X_test)\n",
    "y_pred_our_mlp_model = our_mlp_model.predict(X_test)\n",
    "y_pred_our_xgb_model = our_xgb_model.predict(X_test)\n",
    "y_pred_our_svm_model = our_svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f423f714",
   "metadata": {},
   "source": [
    "## Measuring Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c54ee37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Random Forest (RF): 0.9124087591240876\n",
      "Accuracy for Decission Tree (DT): 0.878345498783455\n",
      "Accuracy for Logistic Regression (LR): 0.0072992700729927005\n",
      "Accuracy for Multi-Layer Perceptron Neural Network (MLP): 0.681265206812652\n",
      "Accuracy for Gradient Boosting (XGB): 0.9099756690997567\n",
      "Accuracy for Support Vector Machine (SVM): 0.7980535279805353\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy for Random Forest (RF):\",metrics.accuracy_score(y_test, y_pred_our_rf_model))\n",
    "print(\"Accuracy for Decission Tree (DT):\",metrics.accuracy_score(y_test, y_pred_our_dt_model))\n",
    "print(\"Accuracy for Logistic Regression (LR):\",metrics.accuracy_score(y_test, y_pred_our_lr_model))\n",
    "print(\"Accuracy for Multi-Layer Perceptron Neural Network (MLP):\",metrics.accuracy_score(y_test, y_pred_our_mlp_model))\n",
    "print(\"Accuracy for Gradient Boosting (XGB):\",metrics.accuracy_score(y_test, y_pred_our_xgb_model))\n",
    "print(\"Accuracy for Support Vector Machine (SVM):\",metrics.accuracy_score(y_test, y_pred_our_svm_model))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb09984",
   "metadata": {},
   "source": [
    "## Precision, Recall, and f1 Score, and AUC for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "64a3cfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.35539814947984083\n",
      "Recall: 0.3\n",
      "f1 score: 0.3219522335901646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred_our_rf_model, average = \"macro\"))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred_our_rf_model, average = \"macro\"))\n",
    "print(\"f1 score:\",metrics.f1_score(y_test,y_pred_our_rf_model, average = \"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "a95447a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16666666666666669, 0.8121119733924611, 0.9940405244338498, 0.8377403846153847, 0.48573127229488705]\n",
      "AUC for RF: 0.6592581642806499\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "u_value= list(y_test.unique())\n",
    "all_auc = []\n",
    "for i in u_value:\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_our_rf_model, pos_label=i)\n",
    "    all_auc.append(metrics.auc(fpr, tpr))\n",
    "print(all_auc)\n",
    "print(\"AUC for RF:\",sum(all_auc)/len(all_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "dc48829e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 3, 1, 4]"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y_test.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fa9b4a",
   "metadata": {},
   "source": [
    "## Precision, Recall, and f1 Score, and AUC for DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "bd1e680a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3095238095238095\n",
      "Recall: 0.29350649350649355\n",
      "f1 score: 0.297999297999298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred_our_dt_model, average = \"macro\"))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred_our_dt_model, average = \"macro\"))\n",
    "print(\"f1 score:\",metrics.f1_score(y_test,y_pred_our_dt_model, average = \"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "810f1c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.9927937915742794, 0.9884783472387764, 0.9788461538461538, 0.9809750297265161]\n",
      "AUC for DT: 0.7882186644771452\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "u_value= list(y_test.unique())\n",
    "all_auc = []\n",
    "for i in u_value:\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_our_dt_model, pos_label=i)\n",
    "    all_auc.append(metrics.auc(fpr, tpr))\n",
    "print(all_auc)\n",
    "print(\"AUC for DT:\",sum(all_auc)/len(all_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0852fd30",
   "metadata": {},
   "source": [
    "## Precision, Recall, and f1 Score, and AUC for LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "84ebf9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.029691211401425176\n",
      "Recall: 0.06570526247945603\n",
      "f1 score: 0.01753361167273814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred_our_lr_model, average = \"micro\"))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred_our_lr_model, average = \"macro\"))\n",
    "print(\"f1 score:\",metrics.f1_score(y_test,y_pred_our_lr_model, average = \"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "4937d00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3850461814171492, 0.6560421286031042, 0.5154946364719905, 0.6072115384615384, 0.011890606420927485]\n",
      "AUC for LR: 0.43513701827494194\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "u_value= list(y_test.unique())\n",
    "all_auc = []\n",
    "for i in u_value:\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_our_lr_model, pos_label=i)\n",
    "    all_auc.append(metrics.auc(fpr, tpr))\n",
    "print(all_auc)\n",
    "print(\"AUC for LR:\",sum(all_auc)/len(all_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255e31df",
   "metadata": {},
   "source": [
    "## Precision, Recall, and f1 Score, and AUC for MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "efa952b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.24617546874057997\n",
      "Recall: 0.30667343409278897\n",
      "f1 score: 0.2667093791397808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred_our_mlp_model, average = \"macro\"))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred_our_mlp_model, average = \"macro\"))\n",
    "print(\"f1 score:\",metrics.f1_score(y_test,y_pred_our_mlp_model, average = \"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "930b09ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1770402536531569, 0.858259423503326, 0.6301152165276122, 0.8141225961538461, 0.46076099881093935]\n",
      "AUC for MLP: 0.5880596977297761\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "u_value= list(y_test.unique())\n",
    "all_auc = []\n",
    "for i in u_value:\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_our_mlp_model, pos_label=i)\n",
    "    all_auc.append(metrics.auc(fpr, tpr))\n",
    "print(all_auc)\n",
    "print(\"AUC for MLP:\",sum(all_auc)/len(all_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5fae17",
   "metadata": {},
   "source": [
    "## Precision, Recall, and f1 Score, and AUC for XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "890e671a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3136363636363636\n",
      "Recall: 0.312987012987013\n",
      "f1 score: 0.31292517006802717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred_our_xgb_model, average = \"macro\"))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred_our_xgb_model, average = \"macro\"))\n",
    "print(\"f1 score:\",metrics.f1_score(y_test,y_pred_our_xgb_model, average = \"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "76053119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.9934866962305987, 0.9896702423520064, 0.9768028846153847, 0.9827586206896552]\n",
      "AUC for XGB: 0.788543688777529\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "u_value= list(y_test.unique())\n",
    "all_auc = []\n",
    "for i in u_value:\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_our_xgb_model, pos_label=i)\n",
    "    all_auc.append(metrics.auc(fpr, tpr))\n",
    "print(all_auc)\n",
    "print(\"AUC for XGB:\",sum(all_auc)/len(all_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa638143",
   "metadata": {},
   "source": [
    "## Precision, Recall, and f1 Score, and AUC for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "c3c80003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9572446555819477\n",
      "Recall: 0.9572446555819477\n",
      "f1 score: 0.9572446555819477\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred_our_svm_model, average = \"micro\"))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred_our_svm_model, average = \"micro\"))\n",
    "print(\"f1 score:\",metrics.f1_score(y_test,y_pred_our_svm_model, average = \"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "bbcb5507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "AUC for SVM: 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "u_value= list(y_test.unique())\n",
    "all_auc = []\n",
    "for i in u_value:\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_our_svm_model, pos_label=i)\n",
    "    all_auc.append(metrics.auc(fpr, tpr))\n",
    "print(all_auc)\n",
    "print(\"AUC for SVM:\",sum(all_auc)/len(all_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84160cf0",
   "metadata": {},
   "source": [
    "## CV Score for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "32b93688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores for RF [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(our_rf_model, X_train, y_train, cv=10)\n",
    "print('Cross-Validation Accuracy Scores for RF', scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301ea177",
   "metadata": {},
   "source": [
    "## After CV: Minimum, Mean, and Maximum Value for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "c78af46c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 1.0)"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = pd.Series(scores)\n",
    "scores.min(), scores.mean(), scores.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "85c03b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy Scores for RF 1.0\n"
     ]
    }
   ],
   "source": [
    "print('Mean Accuracy Scores for RF', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce3590e",
   "metadata": {},
   "source": [
    "## CV Score for DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "fc27f709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores for DT [1.         1.         1.         0.99886364 1.         1.\n",
      " 1.         1.         1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(our_dt_model, X_train, y_train, cv=10)\n",
    "print('Cross-Validation Accuracy Scores for DT', scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab11d8a2",
   "metadata": {},
   "source": [
    "## After CV: Minimum, Mean, and Maximum Value for DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "7db75f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9988636363636364, 0.9998863636363637, 1.0)"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = pd.Series(scores)\n",
    "scores.min(), scores.mean(), scores.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "e92c8eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy Scores for DT 0.9998863636363637\n"
     ]
    }
   ],
   "source": [
    "print('Mean Accuracy Scores for DT', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dac6f33",
   "metadata": {},
   "source": [
    "## CV Score for LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "dfbfea46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores for LR [0.72045455 0.70681818 0.74545455 0.65681818 0.72272727 0.74772727\n",
      " 0.75227273 0.73863636 0.68295455 0.72840909]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(our_lr_model, X_train, y_train, cv=10)\n",
    "print('Cross-Validation Accuracy Scores for LR', scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2671272a",
   "metadata": {},
   "source": [
    "## After CV: Minimum, Mean, and Maximum Value for LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "789406c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6568181818181819, 0.7202272727272726, 0.7522727272727273)"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = pd.Series(scores)\n",
    "scores.min(), scores.mean(), scores.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "9601794b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy Scores for LR 0.7202272727272726\n"
     ]
    }
   ],
   "source": [
    "print('Mean Accuracy Scores for LR', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcf57a5",
   "metadata": {},
   "source": [
    "## CV Score for MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "ebe7f6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores for MLP [0.99659091 0.99090909 0.99090909 0.9875     0.99545455 0.9875\n",
      " 0.99431818 0.99772727 0.98522727 0.99318182]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(our_mlp_model, X_train, y_train, cv=10)\n",
    "print('Cross-Validation Accuracy Scores for MLP', scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3936358c",
   "metadata": {},
   "source": [
    "## After CV: Minimum, Mean, and Maximum Value for MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "88582931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9852272727272727, 0.9919318181818181, 0.9977272727272727)"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = pd.Series(scores)\n",
    "scores.min(), scores.mean(), scores.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "e7d873b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy Scores for MLP 0.9919318181818181\n"
     ]
    }
   ],
   "source": [
    "print('Mean Accuracy Scores for MLP', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814bc73d",
   "metadata": {},
   "source": [
    "## CV Score for XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "91dd3851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores for XGB [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(our_xgb_model, X_train, y_train, cv=10)\n",
    "print('Cross-Validation Accuracy Scores for XGB', scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9bf550",
   "metadata": {},
   "source": [
    "## After CV: Minimum, Mean, and Maximum Value for XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "5f8cac03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 1.0)"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = pd.Series(scores)\n",
    "scores.min(), scores.mean(), scores.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "3e5861b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy Scores for XGB 1.0\n"
     ]
    }
   ],
   "source": [
    "print('Mean Accuracy Scores for XGB', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48f15c3",
   "metadata": {},
   "source": [
    "## CV Score for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "095b4059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores for SVM [0.2289282  0.22476587 0.22060354 0.22083333 0.25       0.33229167\n",
      " 0.32604167 0.253125   0.25625    0.228125  ]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(our_svm_model, X_train, y_train, cv=10)\n",
    "print('Cross-Validation Accuracy Scores for SVM', scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f82ffe",
   "metadata": {},
   "source": [
    "## After CV: Minimum, Mean, and Maximum Value for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "833c0f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.12521150592216582, 0.2216816435725065, 0.43243243243243246)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = pd.Series(scores)\n",
    "scores.min(), scores.mean(), scores.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5c73ac4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy Scores for XGB 0.2216816435725065\n"
     ]
    }
   ],
   "source": [
    "print('Mean Accuracy Scores for XGB', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4f20cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5b5840",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
